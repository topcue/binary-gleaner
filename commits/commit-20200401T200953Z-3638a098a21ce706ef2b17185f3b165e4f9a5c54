{
  "sha": "3638a098a21ce706ef2b17185f3b165e4f9a5c54",
  "node_id": "MDY6Q29tbWl0MTM4Njg2ODE6MzYzOGEwOThhMjFjZTcwNmVmMmIxNzE4NWYzYjE2NWU0ZjlhNWM1NA==",
  "commit": {
    "author": {
      "name": "Tom Tromey",
      "email": "tom@tromey.com",
      "date": "2020-04-01T20:09:52Z"
    },
    "committer": {
      "name": "Tom Tromey",
      "email": "tromey@adacore.com",
      "date": "2020-04-01T20:09:53Z"
    },
    "message": "Add _Complex type support to C parser\n\nThis changes the C parser to add support for complex types in casts.\n\ngdb/ChangeLog\n2020-04-01  Tom Tromey  <tom@tromey.com>\n\n\t* c-exp.y (FLOAT_KEYWORD, COMPLEX): New tokens.\n\t(scalar_type): New rule, from typebase.\n\t(typebase): Use scalar_type.  Recognize complex types.\n\t(field_name): Handle FLOAT_KEYWORD.\n\t(ident_tokens): Add _Complex and __complex__.\n\ngdb/testsuite/ChangeLog\n2020-04-01  Tom Tromey  <tom@tromey.com>\n\n\t* gdb.base/complex-parts.exp: Add type tests.",
    "tree": {
      "sha": "2e28dcfa81cff0a6b027e967326e75802440f660",
      "url": "https://api.github.com/repos/bminor/binutils-gdb/git/trees/2e28dcfa81cff0a6b027e967326e75802440f660"
    },
    "url": "https://api.github.com/repos/bminor/binutils-gdb/git/commits/3638a098a21ce706ef2b17185f3b165e4f9a5c54",
    "comment_count": 0,
    "verification": {
      "verified": false,
      "reason": "unsigned",
      "signature": null,
      "payload": null
    }
  },
  "url": "https://api.github.com/repos/bminor/binutils-gdb/commits/3638a098a21ce706ef2b17185f3b165e4f9a5c54",
  "html_url": "https://github.com/bminor/binutils-gdb/commit/3638a098a21ce706ef2b17185f3b165e4f9a5c54",
  "comments_url": "https://api.github.com/repos/bminor/binutils-gdb/commits/3638a098a21ce706ef2b17185f3b165e4f9a5c54/comments",
  "author": {
    "login": "tromey",
    "id": 1557670,
    "node_id": "MDQ6VXNlcjE1NTc2NzA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1557670?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/tromey",
    "html_url": "https://github.com/tromey",
    "followers_url": "https://api.github.com/users/tromey/followers",
    "following_url": "https://api.github.com/users/tromey/following{/other_user}",
    "gists_url": "https://api.github.com/users/tromey/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/tromey/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/tromey/subscriptions",
    "organizations_url": "https://api.github.com/users/tromey/orgs",
    "repos_url": "https://api.github.com/users/tromey/repos",
    "events_url": "https://api.github.com/users/tromey/events{/privacy}",
    "received_events_url": "https://api.github.com/users/tromey/received_events",
    "type": "User",
    "site_admin": false
  },
  "committer": {
    "login": "tromey",
    "id": 1557670,
    "node_id": "MDQ6VXNlcjE1NTc2NzA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1557670?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/tromey",
    "html_url": "https://github.com/tromey",
    "followers_url": "https://api.github.com/users/tromey/followers",
    "following_url": "https://api.github.com/users/tromey/following{/other_user}",
    "gists_url": "https://api.github.com/users/tromey/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/tromey/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/tromey/subscriptions",
    "organizations_url": "https://api.github.com/users/tromey/orgs",
    "repos_url": "https://api.github.com/users/tromey/repos",
    "events_url": "https://api.github.com/users/tromey/events{/privacy}",
    "received_events_url": "https://api.github.com/users/tromey/received_events",
    "type": "User",
    "site_admin": false
  },
  "parents": [
    {
      "sha": "c34e87146628a14cf662dca46aac893d06502f52",
      "url": "https://api.github.com/repos/bminor/binutils-gdb/commits/c34e87146628a14cf662dca46aac893d06502f52",
      "html_url": "https://github.com/bminor/binutils-gdb/commit/c34e87146628a14cf662dca46aac893d06502f52"
    }
  ],
  "stats": {
    "total": 98,
    "additions": 68,
    "deletions": 30
  },
  "files": [
    {
      "sha": "61d30070e374aed0250dd838c5fb068eab337f32",
      "filename": "gdb/ChangeLog",
      "status": "modified",
      "additions": 8,
      "deletions": 0,
      "changes": 8,
      "blob_url": "https://github.com/bminor/binutils-gdb/blob/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/ChangeLog",
      "raw_url": "https://github.com/bminor/binutils-gdb/raw/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/ChangeLog",
      "contents_url": "https://api.github.com/repos/bminor/binutils-gdb/contents/gdb/ChangeLog?ref=3638a098a21ce706ef2b17185f3b165e4f9a5c54",
      "patch": "@@ -1,3 +1,11 @@\n+2020-04-01  Tom Tromey  <tom@tromey.com>\n+\n+\t* c-exp.y (FLOAT_KEYWORD, COMPLEX): New tokens.\n+\t(scalar_type): New rule, from typebase.\n+\t(typebase): Use scalar_type.  Recognize complex types.\n+\t(field_name): Handle FLOAT_KEYWORD.\n+\t(ident_tokens): Add _Complex and __complex__.\n+\n 2020-04-01  Tom Tromey  <tom@tromey.com>\n \n \tPR exp/25299:"
    },
    {
      "sha": "feab51a8e2cb356223cf9fea1043403973cabd38",
      "filename": "gdb/c-exp.y",
      "status": "modified",
      "additions": 51,
      "deletions": 30,
      "changes": 81,
      "blob_url": "https://github.com/bminor/binutils-gdb/blob/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/c-exp.y",
      "raw_url": "https://github.com/bminor/binutils-gdb/raw/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/c-exp.y",
      "contents_url": "https://api.github.com/repos/bminor/binutils-gdb/contents/gdb/c-exp.y?ref=3638a098a21ce706ef2b17185f3b165e4f9a5c54",
      "patch": "@@ -175,7 +175,7 @@ static void c_print_token (FILE *file, int type, YYSTYPE value);\n \n %type <voidval> exp exp1 type_exp start variable qualified_name lcurly function_method\n %type <lval> rcurly\n-%type <tval> type typebase\n+%type <tval> type typebase scalar_type\n %type <tvec> nonempty_typelist func_mod parameter_typelist\n /* %type <bval> block */\n \n@@ -239,6 +239,7 @@ static void c_print_token (FILE *file, int type, YYSTYPE value);\n    legal basetypes.  */\n %token SIGNED_KEYWORD LONG SHORT INT_KEYWORD CONST_KEYWORD VOLATILE_KEYWORD DOUBLE_KEYWORD\n %token RESTRICT ATOMIC\n+%token FLOAT_KEYWORD COMPLEX\n \n %token <sval> DOLLAR_VARIABLE\n \n@@ -1331,20 +1332,11 @@ func_mod:\t'(' ')'\n type\t:\tptype\n \t;\n \n-/* Implements (approximately): (type-qualifier)* type-specifier.\n+/* A helper production that recognizes scalar types that can validly\n+   be used with _Complex.  */\n \n-   When type-specifier is only ever a single word, like 'float' then these\n-   arrive as pre-built TYPENAME tokens thanks to the classify_name\n-   function.  However, when a type-specifier can contain multiple words,\n-   for example 'double' can appear as just 'double' or 'long double', and\n-   similarly 'long' can appear as just 'long' or in 'long double', then\n-   these type-specifiers are parsed into their own tokens in the function\n-   lex_one_token and the ident_tokens array.  These separate tokens are all\n-   recognised here.  */\n-typebase\n-\t:\tTYPENAME\n-\t\t\t{ $$ = $1.type; }\n-\t|\tINT_KEYWORD\n+scalar_type:\n+\t\tINT_KEYWORD\n \t\t\t{ $$ = lookup_signed_typename (pstate->language (),\n \t\t\t\t\t\t       \"int\"); }\n \t|\tLONG\n@@ -1427,11 +1419,49 @@ typebase\n \t\t\t\t\t\t\"double\",\n \t\t\t\t\t\tNULL,\n \t\t\t\t\t\t0); }\n+\t|\tFLOAT_KEYWORD\n+\t\t\t{ $$ = lookup_typename (pstate->language (),\n+\t\t\t\t\t\t\"float\",\n+\t\t\t\t\t\tNULL,\n+\t\t\t\t\t\t0); }\n \t|\tLONG DOUBLE_KEYWORD\n \t\t\t{ $$ = lookup_typename (pstate->language (),\n \t\t\t\t\t\t\"long double\",\n \t\t\t\t\t\tNULL,\n \t\t\t\t\t\t0); }\n+\t|\tUNSIGNED type_name\n+\t\t\t{ $$ = lookup_unsigned_typename (pstate->language (),\n+\t\t\t\t\t\t\t TYPE_NAME($2.type)); }\n+\t|\tUNSIGNED\n+\t\t\t{ $$ = lookup_unsigned_typename (pstate->language (),\n+\t\t\t\t\t\t\t \"int\"); }\n+\t|\tSIGNED_KEYWORD type_name\n+\t\t\t{ $$ = lookup_signed_typename (pstate->language (),\n+\t\t\t\t\t\t       TYPE_NAME($2.type)); }\n+\t|\tSIGNED_KEYWORD\n+\t\t\t{ $$ = lookup_signed_typename (pstate->language (),\n+\t\t\t\t\t\t       \"int\"); }\n+\t;\n+\n+/* Implements (approximately): (type-qualifier)* type-specifier.\n+\n+   When type-specifier is only ever a single word, like 'float' then these\n+   arrive as pre-built TYPENAME tokens thanks to the classify_name\n+   function.  However, when a type-specifier can contain multiple words,\n+   for example 'double' can appear as just 'double' or 'long double', and\n+   similarly 'long' can appear as just 'long' or in 'long double', then\n+   these type-specifiers are parsed into their own tokens in the function\n+   lex_one_token and the ident_tokens array.  These separate tokens are all\n+   recognised here.  */\n+typebase\n+\t:\tTYPENAME\n+\t\t\t{ $$ = $1.type; }\n+\t|\tscalar_type\n+\t\t\t{ $$ = $1; }\n+\t|\tCOMPLEX scalar_type\n+\t\t\t{\n+\t\t\t  $$ = init_complex_type (nullptr, $2);\n+\t\t\t}\n \t|\tSTRUCT name\n \t\t\t{ $$\n \t\t\t    = lookup_struct (copy_name ($2).c_str (),\n@@ -1498,18 +1528,6 @@ typebase\n \t\t\t\t\t\t       $2.length);\n \t\t\t  $$ = NULL;\n \t\t\t}\n-\t|\tUNSIGNED type_name\n-\t\t\t{ $$ = lookup_unsigned_typename (pstate->language (),\n-\t\t\t\t\t\t\t TYPE_NAME($2.type)); }\n-\t|\tUNSIGNED\n-\t\t\t{ $$ = lookup_unsigned_typename (pstate->language (),\n-\t\t\t\t\t\t\t \"int\"); }\n-\t|\tSIGNED_KEYWORD type_name\n-\t\t\t{ $$ = lookup_signed_typename (pstate->language (),\n-\t\t\t\t\t\t       TYPE_NAME($2.type)); }\n-\t|\tSIGNED_KEYWORD\n-\t\t\t{ $$ = lookup_signed_typename (pstate->language (),\n-\t\t\t\t\t\t       \"int\"); }\n                 /* It appears that this rule for templates is never\n                    reduced; template recognition happens by lookahead\n                    in the token processing code in yylex. */\n@@ -1735,12 +1753,11 @@ oper:\tOPERATOR NEW\n    match the 'name' rule to appear as fields within a struct.  The example\n    that initially motivated this was the RISC-V target which models the\n    floating point registers as a union with fields called 'float' and\n-   'double'.  The 'float' string becomes a TYPENAME token and can appear\n-   anywhere a 'name' can, however 'double' is its own token,\n-   DOUBLE_KEYWORD, and doesn't match the 'name' rule.*/\n+   'double'.  */\n field_name\n \t:\tname\n \t|\tDOUBLE_KEYWORD { $$ = typename_stoken (\"double\"); }\n+\t|\tFLOAT_KEYWORD { $$ = typename_stoken (\"float\"); }\n \t|\tINT_KEYWORD { $$ = typename_stoken (\"int\"); }\n \t|\tLONG { $$ = typename_stoken (\"long\"); }\n \t|\tSHORT { $$ = typename_stoken (\"short\"); }\n@@ -2472,7 +2489,7 @@ static const struct token tokentab2[] =\n /* Identifier-like tokens.  Only type-specifiers than can appear in\n    multi-word type names (for example 'double' can appear in 'long\n    double') need to be listed here.  type-specifiers that are only ever\n-   single word (like 'float') are handled by the classify_name function.  */\n+   single word (like 'char') are handled by the classify_name function.  */\n static const struct token ident_tokens[] =\n   {\n     {\"unsigned\", UNSIGNED, OP_NULL, 0},\n@@ -2484,6 +2501,7 @@ static const struct token ident_tokens[] =\n     {\"_Alignof\", ALIGNOF, OP_NULL, 0},\n     {\"alignof\", ALIGNOF, OP_NULL, FLAG_CXX},\n     {\"double\", DOUBLE_KEYWORD, OP_NULL, 0},\n+    {\"float\", FLOAT_KEYWORD, OP_NULL, 0},\n     {\"false\", FALSEKEYWORD, OP_NULL, FLAG_CXX},\n     {\"class\", CLASS, OP_NULL, FLAG_CXX},\n     {\"union\", UNION, OP_NULL, 0},\n@@ -2495,6 +2513,9 @@ static const struct token ident_tokens[] =\n     {\"_Atomic\", ATOMIC, OP_NULL, 0},\n     {\"enum\", ENUM, OP_NULL, 0},\n     {\"long\", LONG, OP_NULL, 0},\n+    {\"_Complex\", COMPLEX, OP_NULL, 0},\n+    {\"__complex__\", COMPLEX, OP_NULL, 0},\n+\n     {\"true\", TRUEKEYWORD, OP_NULL, FLAG_CXX},\n     {\"int\", INT_KEYWORD, OP_NULL, 0},\n     {\"new\", NEW, OP_NULL, FLAG_CXX},"
    },
    {
      "sha": "f885b93ecd9de1238ce8aa42dea6d9d7fa49d979",
      "filename": "gdb/testsuite/ChangeLog",
      "status": "modified",
      "additions": 4,
      "deletions": 0,
      "changes": 4,
      "blob_url": "https://github.com/bminor/binutils-gdb/blob/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/testsuite/ChangeLog",
      "raw_url": "https://github.com/bminor/binutils-gdb/raw/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/testsuite/ChangeLog",
      "contents_url": "https://api.github.com/repos/bminor/binutils-gdb/contents/gdb/testsuite/ChangeLog?ref=3638a098a21ce706ef2b17185f3b165e4f9a5c54",
      "patch": "@@ -1,3 +1,7 @@\n+2020-04-01  Tom Tromey  <tom@tromey.com>\n+\n+\t* gdb.base/complex-parts.exp: Add type tests.\n+\n 2020-04-01  Tom Tromey  <tom@tromey.com>\n \n \t* gdb.base/complex-parts.exp: Add arithmetic tests."
    },
    {
      "sha": "38aad395ad267035562109db6c4811657aec1451",
      "filename": "gdb/testsuite/gdb.base/complex-parts.exp",
      "status": "modified",
      "additions": 5,
      "deletions": 0,
      "changes": 5,
      "blob_url": "https://github.com/bminor/binutils-gdb/blob/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/testsuite/gdb.base/complex-parts.exp",
      "raw_url": "https://github.com/bminor/binutils-gdb/raw/3638a098a21ce706ef2b17185f3b165e4f9a5c54/gdb/testsuite/gdb.base/complex-parts.exp",
      "contents_url": "https://api.github.com/repos/bminor/binutils-gdb/contents/gdb/testsuite/gdb.base/complex-parts.exp?ref=3638a098a21ce706ef2b17185f3b165e4f9a5c54",
      "patch": "@@ -86,3 +86,8 @@ gdb_test \"print (5 + 7i) != (8 + 7i)\" \" = 1\"\n gdb_test \"print (5 + 7i) != (5 + 92i)\" \" = 1\"\n \n gdb_test \"print (20 - 4i) / (3 + 2i)\" \" = 4 \\\\+ -4i\"\n+\n+gdb_test \"print (_Complex int) 4\" \" = 4 \\\\+ 0i\"\n+gdb_test \"print (_Complex float) 4.5\" \" = 4.5 \\\\+ 0i\"\n+gdb_test \"ptype __complex__ short\" \" = _Complex short\"\n+gdb_test \"print (_Complex int) (23.75 + 8.88i)\" \" = 23 \\\\+ 8i\""
    }
  ]
}