{
  "sha": "0e42221ac2cea234fe7a35797475f55f3d304b92",
  "node_id": "C_kwDOANOeidoAKDBlNDIyMjFhYzJjZWEyMzRmZTdhMzU3OTc0NzVmNTVmM2QzMDRiOTI",
  "commit": {
    "author": {
      "name": "Andrew Burgess",
      "email": "aburgess@redhat.com",
      "date": "2021-11-26T14:34:27Z"
    },
    "committer": {
      "name": "Andrew Burgess",
      "email": "aburgess@redhat.com",
      "date": "2022-01-12T11:33:14Z"
    },
    "message": "gdb: erase items from the source_cache::m_offset_cache\n\nThe source_cache class has two member variables m_source_map, which\nstores the file contents, and m_offset_cache, which stores offsets\ninto the file contents.\n\nAs source files are read the contents of the file, as well as the\noffset data, are stored in the cache using these two member variables.\n\nWhenever GDB needs either the files contents, or the offset data,\nsource_cache::ensure is called.  This function looks for the file in\nm_source_map, and if it's found then this implies the file is also in\nm_offset_cache, and we're done.\n\nIf the file is not in m_source_map then GDB calls\nsource_cache::get_plain_source_lines to open the file and read its\ncontents.  ::get_plain_source_lines also calculates the offset data,\nwhich is then inserted into m_offset_cache.\n\nBack in ::ensure, the file contents are added into m_source_map.  And\nfinally, if m_source_map contains more than MAX_ENTRIES, an entry is\nremoved from m_source_map.\n\nThe problem is entries are not removed from m_offset_cache at the same\ntime.\n\nThis means that if a program contains enough source files, GDB will\nhold at most MAX_ENTRIES cached source file contents, but can contain\noffsets data for every source file.\n\nNow, the offsets data is going to be smaller than the cached file\ncontents, so maybe there's no harm here.  But, when we reload the file\ncontents we always recalculate the offsets data.  And, when we\n::get_line_charpos asking for offset data we still call ::ensure which\nwill ends up loading and caching the file contents.\n\nSo, given the current code does the work of reloading the offset data\nanyway, we may as well save memory by capping m_offset_cache to\nMAX_ENTRIES just like we do m_source_map.\n\nThat's what this commit does.\n\nThere should be no user visible changes after this commit, except for\never so slightly lower memory usage in some cases.",
    "tree": {
      "sha": "5793d33c4af7e23b45a057da20f1a413d581c029",
      "url": "https://api.github.com/repos/bminor/binutils-gdb/git/trees/5793d33c4af7e23b45a057da20f1a413d581c029"
    },
    "url": "https://api.github.com/repos/bminor/binutils-gdb/git/commits/0e42221ac2cea234fe7a35797475f55f3d304b92",
    "comment_count": 0,
    "verification": {
      "verified": false,
      "reason": "unsigned",
      "signature": null,
      "payload": null
    }
  },
  "url": "https://api.github.com/repos/bminor/binutils-gdb/commits/0e42221ac2cea234fe7a35797475f55f3d304b92",
  "html_url": "https://github.com/bminor/binutils-gdb/commit/0e42221ac2cea234fe7a35797475f55f3d304b92",
  "comments_url": "https://api.github.com/repos/bminor/binutils-gdb/commits/0e42221ac2cea234fe7a35797475f55f3d304b92/comments",
  "author": null,
  "committer": null,
  "parents": [
    {
      "sha": "393707788800b05448201fbb184ba758e26960fd",
      "url": "https://api.github.com/repos/bminor/binutils-gdb/commits/393707788800b05448201fbb184ba758e26960fd",
      "html_url": "https://github.com/bminor/binutils-gdb/commit/393707788800b05448201fbb184ba758e26960fd"
    }
  ],
  "stats": {
    "total": 11,
    "additions": 7,
    "deletions": 4
  },
  "files": [
    {
      "sha": "7016476730a6bf7ee60acee8b35b2ba48fa62ba4",
      "filename": "gdb/source-cache.c",
      "status": "modified",
      "additions": 7,
      "deletions": 4,
      "changes": 11,
      "blob_url": "https://github.com/bminor/binutils-gdb/blob/0e42221ac2cea234fe7a35797475f55f3d304b92/gdb/source-cache.c",
      "raw_url": "https://github.com/bminor/binutils-gdb/raw/0e42221ac2cea234fe7a35797475f55f3d304b92/gdb/source-cache.c",
      "contents_url": "https://api.github.com/repos/bminor/binutils-gdb/contents/gdb/source-cache.c?ref=0e42221ac2cea234fe7a35797475f55f3d304b92",
      "patch": "@@ -162,9 +162,8 @@ source_cache::ensure (struct symtab *s)\n     {\n       if (m_source_map[i].fullname == fullname)\n \t{\n-\t  /* This should always hold, because we create the file\n-\t     offsets when reading the file, and never free them\n-\t     without also clearing the contents cache.  */\n+\t  /* This should always hold, because we create the file offsets\n+\t     when reading the file.  */\n \t  gdb_assert (m_offset_cache.find (fullname)\n \t\t      != m_offset_cache.end ());\n \t  /* Not strictly LRU, but at least ensure that the most\n@@ -240,7 +239,11 @@ source_cache::ensure (struct symtab *s)\n   m_source_map.push_back (std::move (result));\n \n   if (m_source_map.size () > MAX_ENTRIES)\n-    m_source_map.erase (m_source_map.begin ());\n+    {\n+      auto iter = m_source_map.begin ();\n+      m_offset_cache.erase (iter->fullname);\n+      m_source_map.erase (iter);\n+    }\n \n   return true;\n }"
    }
  ]
}